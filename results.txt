First attempts
roBERTa 0 layers: 0.7809
roBERTa 1 layers: 0.8261
roBERTa 2 layers no embedding: 0.8319
roBERTa 6 layers no embedding ~0.84
roBERTa 12 layers no embedding ~0.852
roBERTa 6 layers no embedding clean_tweet 0.8929
roBERTa 12 layers no embedding no preprocessing ~0.83
roBERTa 12 layers with embedding no preprocessing 0.8266

-------------------------------------------------------------

BATCH_SIZE 32
learning_rate 5e-5
dropout classification 0.1
num_epoch 1
MAX_LEN 128/512 (BERT 128 / roBERTa 512)

roBERTa 12 layers no embedding clean_tweet
mean acc:  0.8923125862793351
std acc:  0.0023438754395944676
ON KAGGLE PUBLIC: 0.893

roBERTa 12 layers with embedding clean_tweet
mean acc:  0.89891753196 based on 4 fold (1 fold gived 0.5)
std acc:  0.0025041120717059

roBERTa 12 layers with embedding clean_tweet and custom nn
mean acc:  0.8922649700898304
std acc:  0.002273580409090531

BERT 12 layers no embedding clean_tweet 
mean: 0.89558 std: 0.00126
ON KAGGLE PUBLIC: 0.8968

roBERTa 12 layers with embedding partial_clean_tweet
mean acc:  0.902438028929836
std acc:  0.0021023840899968478

-------------------------------------------------------------
BATCH_SIZE 16
learning_rate 2e-5
dropout classification 0.15
MAX_LEN 128/512 (BERT 128 / roBERTa 128)

num_epochs 1

BERT 12 layers with embedding partial_clean_tweet (BEST on BERT)
mean acc: 0.9126479002860973
std acc:  0.0026264475316819112
ON KAGGLE PUBLIC: 0.90180

roBERTa 12 layers with embedding partial_clean_tweet
mean acc:  0.9056603245103336
std acc:  0.0024353505267768684

num_epochs 2

roBERTa 12 layers with embedding partial_clean_tweet 
mean acc:  0.907185242982614
std acc:  0.0029945574861834656

num_epochs 3

roBERTa 12 layers with embedding partial_clean_tweet
mean acc:  0.9062641298041333
std acc:  0.0024089994517277726

-------------------------------------------------------------

BATCH_SIZE 32
learning_rate 2e-5
dropout classification 0.15
MAX_LEN 128/512 (BERT 128 / roBERTa 128)

num_epochs 1

roBERTa 12 layers with embedding partial_clean_tweet
mean acc:  0.9057519556649261
std acc:  0.002426953272849001

num_epochs 2

roBERTa 12 layers with embedding partial_clean_tweet (BEST on roBERTa)
mean acc:  0.9076530020206871
std acc:  0.0024907350080335387

num_epochs 3

roBERTa 12 layers with embedding partial_clean_tweet
...