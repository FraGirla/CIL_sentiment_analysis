{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from string import punctuation                   # to extract the puntuation symbols\n",
    "\n",
    "from nltk.tokenize import word_tokenize          # to divide strings into tokens\n",
    "from nltk.stem import WordNetLemmatizer          # to lemmatize the tokens\n",
    "from nltk.corpus import stopwords                # to remove the stopwords \n",
    "#import pos tagger\n",
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 tweets loaded\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "ids = []\n",
    "def load_tweets(filename):\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.split(',')\n",
    "            #join the tweet from index 1 to the end\n",
    "            ids.append(int(line[0]))\n",
    "            line = ','.join(line[1:])\n",
    "            tweets.append(line.rstrip())\n",
    "load_tweets('twitter-datasets/test_data.txt')\n",
    "\n",
    "# Convert to NumPy array to facilitate indexing\n",
    "tweets = np.array(tweets)\n",
    "\n",
    "print(f'{len(tweets)} tweets loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = pd.DataFrame({'tweet': tweets},index=ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sea doo pro sea scooter ( sports with the port...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;user&gt; shucks well i work all week so now i ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i cant stay away from bug thats my baby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;user&gt; no ma'am ! ! ! lol im perfectly fine an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>whenever i fall asleep watching the tv , i alw...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet\n",
       "1  sea doo pro sea scooter ( sports with the port...\n",
       "2  <user> shucks well i work all week so now i ca...\n",
       "3            i cant stay away from bug thats my baby\n",
       "4  <user> no ma'am ! ! ! lol im perfectly fine an...\n",
       "5  whenever i fall asleep watching the tv , i alw..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    words = [w for w in text if w not in stopwords.words('english')]\n",
    "    return words \n",
    "\n",
    "def clean_text(text):\n",
    "    '''Make text lowercase, remove links,remove punctuation\n",
    "    and remove words containing numbers.'''\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'<url>', '', text)\n",
    "    #text = re.sub(r'<user>', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text\n",
    "\n",
    "tweets_df['clean_tweet'] = tweets_df['tweet'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df['tokenized_tweet'] = tweets_df['clean_tweet'].apply(lambda x: word_tokenize(x))\n",
    "tweets_df['tokenized_tweet_no_stopwords'] = tweets_df['tokenized_tweet'].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatize with pos tag\n",
    "def lemmatize_with_pos_tag(tokenized_text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    pos_tagged_text = pos_tag(tokenized_text)\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token, pos=tag[0].lower()) if tag[0].lower() in ['a','n','v'] else lemmatizer.lemmatize(token) for token, tag in pos_tagged_text]\n",
    "    return lemmatized_tokens\n",
    "tweets_df['clean_tweet_tokenized_lemmatized'] = tweets_df['tokenized_tweet_no_stopwords'].apply(lambda x: lemmatize_with_pos_tag(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = ['tweet', 'clean_tweet', 'tokenized_tweet']\n",
    "#tweets_df = tweets_df.drop(drop_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the list of tokens into a string\n",
    "tweets_df['clean_tweet_tokenized_lemmatized'] = tweets_df['clean_tweet_tokenized_lemmatized'].apply(lambda x: ' '.join(x))\n",
    "tweets_df['tokenized_tweet'] = tweets_df['tokenized_tweet'].apply(lambda x: ' '.join(x))\n",
    "tweets_df['tokenized_tweet_no_stopwords'] = tweets_df['tokenized_tweet_no_stopwords'].apply(lambda x: ' '.join(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>tokenized_tweet</th>\n",
       "      <th>tokenized_tweet_no_stopwords</th>\n",
       "      <th>clean_tweet_tokenized_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sea doo pro sea scooter ( sports with the port...</td>\n",
       "      <td>sea doo pro sea scooter  sports with the porta...</td>\n",
       "      <td>sea doo pro sea scooter sports with the portab...</td>\n",
       "      <td>sea doo pro sea scooter sports portable seadoo...</td>\n",
       "      <td>sea doo pro sea scooter sport portable seadoo ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;user&gt; shucks well i work all week so now i ca...</td>\n",
       "      <td>user shucks well i work all week so now i cant...</td>\n",
       "      <td>user shucks well i work all week so now i cant...</td>\n",
       "      <td>user shucks well work week cant come cheer oh ...</td>\n",
       "      <td>user shuck well work week cant come cheer oh p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i cant stay away from bug thats my baby</td>\n",
       "      <td>i cant stay away from bug thats my baby</td>\n",
       "      <td>i cant stay away from bug thats my baby</td>\n",
       "      <td>cant stay away bug thats baby</td>\n",
       "      <td>cant stay away bug thats baby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;user&gt; no ma'am ! ! ! lol im perfectly fine an...</td>\n",
       "      <td>user no maam    lol im perfectly fine and not ...</td>\n",
       "      <td>user no maam lol im perfectly fine and not con...</td>\n",
       "      <td>user maam lol im perfectly fine contagious any...</td>\n",
       "      <td>user maam lol im perfectly fine contagious any...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>whenever i fall asleep watching the tv , i alw...</td>\n",
       "      <td>whenever i fall asleep watching the tv  i alwa...</td>\n",
       "      <td>whenever i fall asleep watching the tv i alway...</td>\n",
       "      <td>whenever fall asleep watching tv always wake h...</td>\n",
       "      <td>whenever fall asleep watch tv always wake head...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  \\\n",
       "1  sea doo pro sea scooter ( sports with the port...   \n",
       "2  <user> shucks well i work all week so now i ca...   \n",
       "3            i cant stay away from bug thats my baby   \n",
       "4  <user> no ma'am ! ! ! lol im perfectly fine an...   \n",
       "5  whenever i fall asleep watching the tv , i alw...   \n",
       "\n",
       "                                         clean_tweet  \\\n",
       "1  sea doo pro sea scooter  sports with the porta...   \n",
       "2  user shucks well i work all week so now i cant...   \n",
       "3            i cant stay away from bug thats my baby   \n",
       "4  user no maam    lol im perfectly fine and not ...   \n",
       "5  whenever i fall asleep watching the tv  i alwa...   \n",
       "\n",
       "                                     tokenized_tweet  \\\n",
       "1  sea doo pro sea scooter sports with the portab...   \n",
       "2  user shucks well i work all week so now i cant...   \n",
       "3            i cant stay away from bug thats my baby   \n",
       "4  user no maam lol im perfectly fine and not con...   \n",
       "5  whenever i fall asleep watching the tv i alway...   \n",
       "\n",
       "                        tokenized_tweet_no_stopwords  \\\n",
       "1  sea doo pro sea scooter sports portable seadoo...   \n",
       "2  user shucks well work week cant come cheer oh ...   \n",
       "3                      cant stay away bug thats baby   \n",
       "4  user maam lol im perfectly fine contagious any...   \n",
       "5  whenever fall asleep watching tv always wake h...   \n",
       "\n",
       "                    clean_tweet_tokenized_lemmatized  \n",
       "1  sea doo pro sea scooter sport portable seadoo ...  \n",
       "2  user shuck well work week cant come cheer oh p...  \n",
       "3                      cant stay away bug thats baby  \n",
       "4  user maam lol im perfectly fine contagious any...  \n",
       "5  whenever fall asleep watch tv always wake head...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename clean_tweet_tokenized_lemmatized to text\n",
    "tweets_df['text'] = tweets_df['clean_tweet_tokenized_lemmatized']\n",
    "tweets_df.drop('clean_tweet_tokenized_lemmatized',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the data  \n",
    "tweets_df.to_csv('preprocessed/test_full.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10000 entries, 1 to 10000\n",
      "Data columns (total 5 columns):\n",
      " #   Column                        Non-Null Count  Dtype \n",
      "---  ------                        --------------  ----- \n",
      " 0   tweet                         10000 non-null  object\n",
      " 1   clean_tweet                   10000 non-null  object\n",
      " 2   tokenized_tweet               10000 non-null  object\n",
      " 3   tokenized_tweet_no_stopwords  10000 non-null  object\n",
      " 4   text                          10000 non-null  object\n",
      "dtypes: object(5)\n",
      "memory usage: 468.8+ KB\n"
     ]
    }
   ],
   "source": [
    "#check for nan\n",
    "tweets_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
