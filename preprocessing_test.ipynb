{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from string import punctuation                   # to extract the puntuation symbols\n",
    "\n",
    "from nltk.tokenize import word_tokenize          # to divide strings into tokens\n",
    "from nltk.stem import WordNetLemmatizer          # to lemmatize the tokens\n",
    "from nltk.corpus import stopwords                # to remove the stopwords \n",
    "#import pos tagger\n",
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 tweets loaded\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "def load_tweets(filename):\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            tweets.append(line.rstrip())\n",
    "load_tweets('twitter-datasets/test_data.txt')\n",
    "\n",
    "# Convert to NumPy array to facilitate indexing\n",
    "tweets = np.array(tweets)\n",
    "\n",
    "print(f'{len(tweets)} tweets loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = pd.DataFrame({'tweet': tweets})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1,sea doo pro sea scooter ( sports with the po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2,&lt;user&gt; shucks well i work all week so now i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3,i cant stay away from bug thats my baby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4,&lt;user&gt; no ma'am ! ! ! lol im perfectly fine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5,whenever i fall asleep watching the tv , i a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet\n",
       "0  1,sea doo pro sea scooter ( sports with the po...\n",
       "1  2,<user> shucks well i work all week so now i ...\n",
       "2          3,i cant stay away from bug thats my baby\n",
       "3  4,<user> no ma'am ! ! ! lol im perfectly fine ...\n",
       "4  5,whenever i fall asleep watching the tv , i a..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    words = [w for w in text if w not in stopwords.words('english')]\n",
    "    return words \n",
    "\n",
    "def clean_text(text):\n",
    "    '''Make text lowercase, remove links,remove punctuation\n",
    "    and remove words containing numbers.'''\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'<url>', '', text)\n",
    "    #text = re.sub(r'<user>', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text\n",
    "\n",
    "tweets_df['clean_tweet'] = tweets_df['tweet'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df['clean_tweet'] = tweets_df['clean_tweet'].apply(lambda x: word_tokenize(x))\n",
    "tweets_df['tokenized_tweet'] = tweets_df['clean_tweet'].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatize with pos tag\n",
    "def lemmatize_with_pos_tag(tokenized_text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    pos_tagged_text = pos_tag(tokenized_text)\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token, pos=tag[0].lower()) if tag[0].lower() in ['a','n','v'] else lemmatizer.lemmatize(token) for token, tag in pos_tagged_text]\n",
    "    return lemmatized_tokens\n",
    "tweets_df['clean_tweet_tokenized_lemmatized'] = tweets_df['tokenized_tweet'].apply(lambda x: lemmatize_with_pos_tag(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = ['tweet', 'clean_tweet', 'tokenized_tweet']\n",
    "#tweets_df = tweets_df.drop(drop_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the list of tokens into a string\n",
    "tweets_df['clean_tweet_tokenized_lemmatized'] = tweets_df['clean_tweet_tokenized_lemmatized'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>tokenized_tweet</th>\n",
       "      <th>clean_tweet_tokenized_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1,sea doo pro sea scooter ( sports with the po...</td>\n",
       "      <td>[doo, pro, sea, scooter, sports, with, the, po...</td>\n",
       "      <td>[doo, pro, sea, scooter, sports, portable, sea...</td>\n",
       "      <td>doo pro sea scooter sport portable seadoo seas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2,&lt;user&gt; shucks well i work all week so now i ...</td>\n",
       "      <td>[shucks, well, i, work, all, week, so, now, i,...</td>\n",
       "      <td>[shucks, well, work, week, cant, come, cheer, ...</td>\n",
       "      <td>shuck well work week cant come cheer oh put ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3,i cant stay away from bug thats my baby</td>\n",
       "      <td>[cant, stay, away, from, bug, thats, my, baby]</td>\n",
       "      <td>[cant, stay, away, bug, thats, baby]</td>\n",
       "      <td>cant stay away bug thats baby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4,&lt;user&gt; no ma'am ! ! ! lol im perfectly fine ...</td>\n",
       "      <td>[no, maam, lol, im, perfectly, fine, and, not,...</td>\n",
       "      <td>[maam, lol, im, perfectly, fine, contagious, a...</td>\n",
       "      <td>maam lol im perfectly fine contagious anymore ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5,whenever i fall asleep watching the tv , i a...</td>\n",
       "      <td>[i, fall, asleep, watching, the, tv, i, always...</td>\n",
       "      <td>[fall, asleep, watching, tv, always, wake, hea...</td>\n",
       "      <td>fall asleep watch tv always wake headache</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  \\\n",
       "0  1,sea doo pro sea scooter ( sports with the po...   \n",
       "1  2,<user> shucks well i work all week so now i ...   \n",
       "2          3,i cant stay away from bug thats my baby   \n",
       "3  4,<user> no ma'am ! ! ! lol im perfectly fine ...   \n",
       "4  5,whenever i fall asleep watching the tv , i a...   \n",
       "\n",
       "                                         clean_tweet  \\\n",
       "0  [doo, pro, sea, scooter, sports, with, the, po...   \n",
       "1  [shucks, well, i, work, all, week, so, now, i,...   \n",
       "2     [cant, stay, away, from, bug, thats, my, baby]   \n",
       "3  [no, maam, lol, im, perfectly, fine, and, not,...   \n",
       "4  [i, fall, asleep, watching, the, tv, i, always...   \n",
       "\n",
       "                                     tokenized_tweet  \\\n",
       "0  [doo, pro, sea, scooter, sports, portable, sea...   \n",
       "1  [shucks, well, work, week, cant, come, cheer, ...   \n",
       "2               [cant, stay, away, bug, thats, baby]   \n",
       "3  [maam, lol, im, perfectly, fine, contagious, a...   \n",
       "4  [fall, asleep, watching, tv, always, wake, hea...   \n",
       "\n",
       "                    clean_tweet_tokenized_lemmatized  \n",
       "0  doo pro sea scooter sport portable seadoo seas...  \n",
       "1  shuck well work week cant come cheer oh put ba...  \n",
       "2                      cant stay away bug thats baby  \n",
       "3  maam lol im perfectly fine contagious anymore ...  \n",
       "4          fall asleep watch tv always wake headache  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename clean_tweet_tokenized_lemmatized to text\n",
    "tweets_df['text'] = tweets_df['clean_tweet_tokenized_lemmatized']\n",
    "tweets_df.drop('clean_tweet_tokenized_lemmatized',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the data  \n",
    "tweets_df.to_csv('preprocessed/test_full.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 4 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   tweet            10000 non-null  object\n",
      " 1   clean_tweet      10000 non-null  object\n",
      " 2   tokenized_tweet  10000 non-null  object\n",
      " 3   text             10000 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 312.6+ KB\n"
     ]
    }
   ],
   "source": [
    "#check for nan\n",
    "tweets_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
